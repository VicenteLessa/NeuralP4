{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32174,
     "status": "ok",
     "timestamp": 1716259511383,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "93XXr2GHiBqA",
    "outputId": "426a70a0-e654-4846-dbd0-850c3cc8e0e2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Save timestamp\n",
    "start = time.time()\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0-dev20240611\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8SEnBPkJBjY"
   },
   "source": [
    "### Specify here the NN topology and the dataframe to be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1716259684236,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "CT-15-PmiHZn"
   },
   "outputs": [],
   "source": [
    "#specify the NN topology here:\n",
    "#input_layer_nodes = number_of_attributes\n",
    "number_of_attributes = 2\n",
    "hidden_layer_nodes = 2\n",
    "output_layer_nodes = 2\n",
    "\n",
    "\n",
    "use_case = \"netml-iot\"\n",
    "dataset_folder = f\"../datasets/nprint-raw/{use_case}/\"\n",
    "features_rankings = f\"../datasets/nprint-raw/{use_case}/feature-importance.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d35dDblII_J9"
   },
   "source": [
    "###Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1716259688443,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "tj2cFHLXkoXh"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 500\n",
    "\n",
    "def get_basic_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(hidden_layer_nodes, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_layer_nodes)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaiUaBAuI6HD"
   },
   "source": [
    "###Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2838,
     "status": "ok",
     "timestamp": 1716259736242,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "NLYaSSiIhrgz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "0       2\n",
       "1       1\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "5       2\n",
       "6       2\n",
       "7       2\n",
       "8       1\n",
       "9       1\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      1\n",
       "15      1\n",
       "16      2\n",
       "17      1\n",
       "18      1\n",
       "19      1\n",
       "20      2\n",
       "21      1\n",
       "22      1\n",
       "23      0\n",
       "24      1\n",
       "25      0\n",
       "26      2\n",
       "27      2\n",
       "28      0\n",
       "29      0\n",
       "30      1\n",
       "31      1\n",
       "32      0\n",
       "33      0\n",
       "34      2\n",
       "35      2\n",
       "36      1\n",
       "37      0\n",
       "38      0\n",
       "39      2\n",
       "40      0\n",
       "41      2\n",
       "42      1\n",
       "43      0\n",
       "44      1\n",
       "45      2\n",
       "46      1\n",
       "47      1\n",
       "48      1\n",
       "49      1\n",
       "50      1\n",
       "51      0\n",
       "52      2\n",
       "53      2\n",
       "54      0\n",
       "55      1\n",
       "56      0\n",
       "57      1\n",
       "58      0\n",
       "59      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{dataset_folder}X.csv')\n",
    "df_test = pd.read_csv(f'{dataset_folder}X_val.csv')\n",
    "label_train = pd.read_csv(f'{dataset_folder}y.csv')\n",
    "label_test = pd.read_csv(f'{dataset_folder}y_val.csv')\n",
    "\n",
    "df_train.drop('pcap', axis=1, inplace=True)\n",
    "df_test.drop('pcap', axis=1, inplace=True)\n",
    "label_train.drop('pcap', axis=1, inplace=True)\n",
    "label_test.drop('pcap', axis=1, inplace=True)\n",
    "label_train.rename(columns={'0': 'label'}, inplace=True)\n",
    "label_test.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "# display(df_train)\n",
    "# display(df_test)\n",
    "# display(label_train)\n",
    "display(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1716259749230,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "bHgpzuUgWT0J"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pkt_5_tcp_opt_64</th>\n",
       "      <th>pkt_9_tcp_opt_64</th>\n",
       "      <th>pkt_5_tcp_opt_65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pkt_5_tcp_opt_64  pkt_9_tcp_opt_64  pkt_5_tcp_opt_65\n",
       "0                   1                 0                 0\n",
       "1                   0                 1                 0\n",
       "2                  -1                -1                -1\n",
       "3                   1                 0                 0\n",
       "4                   0                 0                 0\n",
       "..                ...               ...               ...\n",
       "232                 0                 0                 0\n",
       "233                -1                -1                -1\n",
       "234                 0                 0                 1\n",
       "235                -1                 1                -1\n",
       "236                -1                 1                -1\n",
       "\n",
       "[237 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pkt_5_tcp_opt_64</th>\n",
       "      <th>pkt_9_tcp_opt_64</th>\n",
       "      <th>pkt_5_tcp_opt_65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pkt_5_tcp_opt_64  pkt_9_tcp_opt_64  pkt_5_tcp_opt_65\n",
       "0                  1                 1                 0\n",
       "1                 -1                -1                -1\n",
       "2                 -1                -1                -1\n",
       "3                  1                -1                 1\n",
       "4                  0                 0                 0\n",
       "5                  1                 0                 0\n",
       "6                  0                 0                 0\n",
       "7                  1                -1                 1\n",
       "8                  0                -1                 0\n",
       "9                  0                 0                 0\n",
       "10                -1                 1                -1\n",
       "11                -1                -1                -1\n",
       "12                 1                 0                 0\n",
       "13                 0                -1                 0\n",
       "14                 0                 0                 0\n",
       "15                 0                 0                 0\n",
       "16                 1                -1                 1\n",
       "17                 0                -1                 0\n",
       "18                 0                 0                 1\n",
       "19                -1                -1                -1\n",
       "20                 1                 0                 1\n",
       "21                 0                 0                 1\n",
       "22                 0                 0                 0\n",
       "23                -1                -1                -1\n",
       "24                -1                 0                -1\n",
       "25                -1                 0                -1\n",
       "26                 0                 1                 0\n",
       "27                -1                -1                -1\n",
       "28                 0                 0                 0\n",
       "29                -1                 0                -1\n",
       "30                -1                -1                -1\n",
       "31                -1                -1                -1\n",
       "32                 1                 0                 0\n",
       "33                -1                 0                -1\n",
       "34                -1                -1                -1\n",
       "35                 1                 0                 1\n",
       "36                 0                 0                 0\n",
       "37                 1                 1                 0\n",
       "38                -1                 1                -1\n",
       "39                 1                 1                 1\n",
       "40                -1                 1                -1\n",
       "41                 1                 0                 1\n",
       "42                -1                -1                -1\n",
       "43                -1                 1                -1\n",
       "44                 0                -1                 0\n",
       "45                 1                 0                 1\n",
       "46                 0                 0                 0\n",
       "47                 0                 0                 1\n",
       "48                 0                 0                 1\n",
       "49                -1                 0                -1\n",
       "50                 0                 0                 0\n",
       "51                -1                 1                -1\n",
       "52                 1                 1                 1\n",
       "53                 1                 0                 0\n",
       "54                -1                 1                -1\n",
       "55                 0                 0                 1\n",
       "56                -1                 0                -1\n",
       "57                 0                -1                 0\n",
       "58                 0                -1                 0\n",
       "59                 0                 0                 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#select a sub-dataframe with only the top attrs rate by the AUTOGLUON feature importance algorithm\n",
    "#load the file with the rankings\n",
    "features_rankings_df = pd.read_csv(features_rankings)\n",
    "features_rankings_df.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "#make a list with only the best features\n",
    "feature_list = features_rankings_df['Unnamed: 0'].tolist()\n",
    "feature_list = feature_list[:number_of_attributes]\n",
    "# print(feature_list)\n",
    "\n",
    "#select a sub-dataframe with only the 32 top attrs rate by the AUTOGLUON feature importance algorithm\n",
    "df_train = df_train[feature_list]\n",
    "df_test = df_test[feature_list]\n",
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY FOR VIDEO STREAM USE CASE\n",
    "#RTS values conversion for video-streaming use-case\n",
    "# INTEGER = 8\n",
    "\n",
    "# mini = []\n",
    "# maxi = []\n",
    "# column_list = [\"pkt_1_rts\", \"pkt_2_rts\", \"pkt_3_rts\", \"pkt_4_rts\", \"pkt_5_rts\", \"pkt_6_rts\", \"pkt_7_rts\", \"pkt_8_rts\"]\n",
    "# for column_name in column_list:\n",
    "#     mini.append(df_test[column_name].min())\n",
    "#     print(mini)    \n",
    "#     maxi.append(df_test[column_name].max())\n",
    "#     print(maxi)\n",
    "\n",
    "# maximo = max(maxi)\n",
    "# minimo = min(mini)\n",
    "# print(maximo)\n",
    "\n",
    "\n",
    "# display(df_test)\n",
    "# for column_name in column_list:\n",
    "#     aux = []\n",
    "#     for x in df_test[column_name]:\n",
    "#         normalized_value = (x - minimo) / (maximo - minimo)\n",
    "#         scaled_value = normalized_value * (2**INTEGER - 1)\n",
    "#         aux.append(scaled_value)\n",
    "#     df_test[column_name]=aux    \n",
    "# display(df_test)\n",
    "\n",
    "# mini = []\n",
    "# maxi = []\n",
    "# for column_name in column_list:\n",
    "#     mini.append(df_train[column_name].min())\n",
    "#     print(mini)    \n",
    "#     maxi.append(df_train[column_name].max())\n",
    "#     print(maxi)\n",
    "\n",
    "# maximo = max(maxi)\n",
    "# minimo = min(mini)\n",
    "# print(maximo)\n",
    "\n",
    "\n",
    "# display(df_train)\n",
    "# for column_name in column_list:\n",
    "#     aux = []\n",
    "#     for x in df_train[column_name]:\n",
    "#         normalized_value = (x - minimo) / (maximo - minimo)\n",
    "#         scaled_value = normalized_value * (2**INTEGER - 1)\n",
    "#         aux.append(scaled_value)\n",
    "#     df_train[column_name]=aux\n",
    "    \n",
    "# display(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3ngEN5GJTag"
   },
   "source": [
    "### NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29270,
     "status": "ok",
     "timestamp": 1716259884626,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "Axt9vLxMiO-6",
    "outputId": "9e385e82-fa0a-4943-c9c1-abaac3390b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 3 attributes\n",
      "Epoch 1/500\n",
      "1/1 - 1s - 602ms/step - accuracy: 0.1899 - loss: 1.2278\n",
      "Epoch 2/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.1899 - loss: 1.2267\n",
      "Epoch 3/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1899 - loss: 1.2256\n",
      "Epoch 4/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.1899 - loss: 1.2245\n",
      "Epoch 5/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1899 - loss: 1.2234\n",
      "Epoch 6/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.1350 - loss: 1.2223\n",
      "Epoch 7/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.1350 - loss: 1.2213\n",
      "Epoch 8/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1350 - loss: 1.2202\n",
      "Epoch 9/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.1350 - loss: 1.2192\n",
      "Epoch 10/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1350 - loss: 1.2181\n",
      "Epoch 11/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1350 - loss: 1.2171\n",
      "Epoch 12/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.2160\n",
      "Epoch 13/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2149\n",
      "Epoch 14/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2138\n",
      "Epoch 15/500\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.1730 - loss: 1.2127\n",
      "Epoch 16/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2116\n",
      "Epoch 17/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2105\n",
      "Epoch 18/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.2094\n",
      "Epoch 19/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2083\n",
      "Epoch 20/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.1730 - loss: 1.2072\n",
      "Epoch 21/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.2062\n",
      "Epoch 22/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2051\n",
      "Epoch 23/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.2041\n",
      "Epoch 24/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2030\n",
      "Epoch 25/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.2020\n",
      "Epoch 26/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.2010\n",
      "Epoch 27/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.2000\n",
      "Epoch 28/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.1990\n",
      "Epoch 29/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.1980\n",
      "Epoch 30/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.1970\n",
      "Epoch 31/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.1730 - loss: 1.1961\n",
      "Epoch 32/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.1951\n",
      "Epoch 33/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.1730 - loss: 1.1942\n",
      "Epoch 34/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.1730 - loss: 1.1932\n",
      "Epoch 35/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2405 - loss: 1.1923\n",
      "Epoch 36/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2405 - loss: 1.1914\n",
      "Epoch 37/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2405 - loss: 1.1905\n",
      "Epoch 38/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2405 - loss: 1.1896\n",
      "Epoch 39/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2405 - loss: 1.1887\n",
      "Epoch 40/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1878\n",
      "Epoch 41/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1869\n",
      "Epoch 42/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1860\n",
      "Epoch 43/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1852\n",
      "Epoch 44/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1843\n",
      "Epoch 45/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1834\n",
      "Epoch 46/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.2616 - loss: 1.1826\n",
      "Epoch 47/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1817\n",
      "Epoch 48/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1809\n",
      "Epoch 49/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1800\n",
      "Epoch 50/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1792\n",
      "Epoch 51/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1784\n",
      "Epoch 52/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1776\n",
      "Epoch 53/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1767\n",
      "Epoch 54/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1759\n",
      "Epoch 55/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.2616 - loss: 1.1751\n",
      "Epoch 56/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1743\n",
      "Epoch 57/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1735\n",
      "Epoch 58/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.2616 - loss: 1.1727\n",
      "Epoch 59/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1719\n",
      "Epoch 60/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1711\n",
      "Epoch 61/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.2616 - loss: 1.1704\n",
      "Epoch 62/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1696\n",
      "Epoch 63/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1688\n",
      "Epoch 64/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1680\n",
      "Epoch 65/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2616 - loss: 1.1673\n",
      "Epoch 66/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1665\n",
      "Epoch 67/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1657\n",
      "Epoch 68/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1650\n",
      "Epoch 69/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1642\n",
      "Epoch 70/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1635\n",
      "Epoch 71/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1628\n",
      "Epoch 72/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2616 - loss: 1.1620\n",
      "Epoch 73/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1613\n",
      "Epoch 74/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1605\n",
      "Epoch 75/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1598\n",
      "Epoch 76/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1591\n",
      "Epoch 77/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1584\n",
      "Epoch 78/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1577\n",
      "Epoch 79/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1569\n",
      "Epoch 80/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4304 - loss: 1.1562\n",
      "Epoch 81/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1555\n",
      "Epoch 82/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1548\n",
      "Epoch 83/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1541\n",
      "Epoch 84/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1534\n",
      "Epoch 85/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1527\n",
      "Epoch 86/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1520\n",
      "Epoch 87/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1514\n",
      "Epoch 88/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1507\n",
      "Epoch 89/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1500\n",
      "Epoch 90/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1493\n",
      "Epoch 91/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1486\n",
      "Epoch 92/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1480\n",
      "Epoch 93/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4304 - loss: 1.1473\n",
      "Epoch 94/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1466\n",
      "Epoch 95/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1460\n",
      "Epoch 96/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1453\n",
      "Epoch 97/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1447\n",
      "Epoch 98/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1440\n",
      "Epoch 99/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1434\n",
      "Epoch 100/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1427\n",
      "Epoch 101/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1421\n",
      "Epoch 102/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1414\n",
      "Epoch 103/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1408\n",
      "Epoch 104/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1402\n",
      "Epoch 105/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1395\n",
      "Epoch 106/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1389\n",
      "Epoch 107/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1383\n",
      "Epoch 108/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1376\n",
      "Epoch 109/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1370\n",
      "Epoch 110/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1364\n",
      "Epoch 111/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1358\n",
      "Epoch 112/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1352\n",
      "Epoch 113/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4304 - loss: 1.1346\n",
      "Epoch 114/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1340\n",
      "Epoch 115/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1334\n",
      "Epoch 116/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1328\n",
      "Epoch 117/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1322\n",
      "Epoch 118/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1316\n",
      "Epoch 119/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1310\n",
      "Epoch 120/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1304\n",
      "Epoch 121/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1298\n",
      "Epoch 122/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1292\n",
      "Epoch 123/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.4304 - loss: 1.1286\n",
      "Epoch 124/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1281\n",
      "Epoch 125/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1275\n",
      "Epoch 126/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1269\n",
      "Epoch 127/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1263\n",
      "Epoch 128/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1258\n",
      "Epoch 129/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1252\n",
      "Epoch 130/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1246\n",
      "Epoch 131/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1241\n",
      "Epoch 132/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1235\n",
      "Epoch 133/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1229\n",
      "Epoch 134/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1224\n",
      "Epoch 135/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1218\n",
      "Epoch 136/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1213\n",
      "Epoch 137/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1207\n",
      "Epoch 138/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1202\n",
      "Epoch 139/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1197\n",
      "Epoch 140/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1191\n",
      "Epoch 141/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1186\n",
      "Epoch 142/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1180\n",
      "Epoch 143/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1175\n",
      "Epoch 144/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1170\n",
      "Epoch 145/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1164\n",
      "Epoch 146/500\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.4304 - loss: 1.1159\n",
      "Epoch 147/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1154\n",
      "Epoch 148/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1149\n",
      "Epoch 149/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1143\n",
      "Epoch 150/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1138\n",
      "Epoch 151/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1133\n",
      "Epoch 152/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1128\n",
      "Epoch 153/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1123\n",
      "Epoch 154/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4304 - loss: 1.1118\n",
      "Epoch 155/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1113\n",
      "Epoch 156/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1108\n",
      "Epoch 157/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1103\n",
      "Epoch 158/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1098\n",
      "Epoch 159/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1093\n",
      "Epoch 160/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1088\n",
      "Epoch 161/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1083\n",
      "Epoch 162/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1078\n",
      "Epoch 163/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1073\n",
      "Epoch 164/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1068\n",
      "Epoch 165/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1063\n",
      "Epoch 166/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1058\n",
      "Epoch 167/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4304 - loss: 1.1053\n",
      "Epoch 168/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1049\n",
      "Epoch 169/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1044\n",
      "Epoch 170/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1039\n",
      "Epoch 171/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1034\n",
      "Epoch 172/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1030\n",
      "Epoch 173/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1025\n",
      "Epoch 174/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1020\n",
      "Epoch 175/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1015\n",
      "Epoch 176/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.1011\n",
      "Epoch 177/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.1006\n",
      "Epoch 178/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.1002\n",
      "Epoch 179/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0997\n",
      "Epoch 180/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0992\n",
      "Epoch 181/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0988\n",
      "Epoch 182/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0983\n",
      "Epoch 183/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0979\n",
      "Epoch 184/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0974\n",
      "Epoch 185/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0970\n",
      "Epoch 186/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.4304 - loss: 1.0965\n",
      "Epoch 187/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0961\n",
      "Epoch 188/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0956\n",
      "Epoch 189/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0952\n",
      "Epoch 190/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0948\n",
      "Epoch 191/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0943\n",
      "Epoch 192/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0939\n",
      "Epoch 193/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0934\n",
      "Epoch 194/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0930\n",
      "Epoch 195/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0926\n",
      "Epoch 196/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0922\n",
      "Epoch 197/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0917\n",
      "Epoch 198/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0913\n",
      "Epoch 199/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0909\n",
      "Epoch 200/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0905\n",
      "Epoch 201/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0900\n",
      "Epoch 202/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0896\n",
      "Epoch 203/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0892\n",
      "Epoch 204/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.4304 - loss: 1.0888\n",
      "Epoch 205/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0884\n",
      "Epoch 206/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0879\n",
      "Epoch 207/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0875\n",
      "Epoch 208/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0871\n",
      "Epoch 209/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0867\n",
      "Epoch 210/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0863\n",
      "Epoch 211/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0859\n",
      "Epoch 212/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0855\n",
      "Epoch 213/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0851\n",
      "Epoch 214/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0847\n",
      "Epoch 215/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0843\n",
      "Epoch 216/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0839\n",
      "Epoch 217/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0835\n",
      "Epoch 218/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0831\n",
      "Epoch 219/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0827\n",
      "Epoch 220/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0823\n",
      "Epoch 221/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4304 - loss: 1.0819\n",
      "Epoch 222/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4304 - loss: 1.0815\n",
      "Epoch 223/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0812\n",
      "Epoch 224/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0808\n",
      "Epoch 225/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0804\n",
      "Epoch 226/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0800\n",
      "Epoch 227/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0796\n",
      "Epoch 228/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0792\n",
      "Epoch 229/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0789\n",
      "Epoch 230/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0785\n",
      "Epoch 231/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0781\n",
      "Epoch 232/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4304 - loss: 1.0777\n",
      "Epoch 233/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4304 - loss: 1.0774\n",
      "Epoch 234/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4304 - loss: 1.0770\n",
      "Epoch 235/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0766\n",
      "Epoch 236/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4304 - loss: 1.0763\n",
      "Epoch 237/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4304 - loss: 1.0759\n",
      "Epoch 238/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0755\n",
      "Epoch 239/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0752\n",
      "Epoch 240/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4304 - loss: 1.0750\n",
      "Epoch 241/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0747\n",
      "Epoch 242/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4304 - loss: 1.0745\n",
      "Epoch 243/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4304 - loss: 1.0743\n",
      "Epoch 244/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0741\n",
      "Epoch 245/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0739\n",
      "Epoch 246/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0737\n",
      "Epoch 247/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0735\n",
      "Epoch 248/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0732\n",
      "Epoch 249/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4515 - loss: 1.0730\n",
      "Epoch 250/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0728\n",
      "Epoch 251/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0726\n",
      "Epoch 252/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0724\n",
      "Epoch 253/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0722\n",
      "Epoch 254/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0720\n",
      "Epoch 255/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0719\n",
      "Epoch 256/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0717\n",
      "Epoch 257/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0715\n",
      "Epoch 258/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0713\n",
      "Epoch 259/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0711\n",
      "Epoch 260/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0709\n",
      "Epoch 261/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0707\n",
      "Epoch 262/500\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.4515 - loss: 1.0705\n",
      "Epoch 263/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0703\n",
      "Epoch 264/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0702\n",
      "Epoch 265/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0700\n",
      "Epoch 266/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0698\n",
      "Epoch 267/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0696\n",
      "Epoch 268/500\n",
      "1/1 - 0s - 14ms/step - accuracy: 0.4515 - loss: 1.0694\n",
      "Epoch 269/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0693\n",
      "Epoch 270/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0691\n",
      "Epoch 271/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0689\n",
      "Epoch 272/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0687\n",
      "Epoch 273/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0685\n",
      "Epoch 274/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0684\n",
      "Epoch 275/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0682\n",
      "Epoch 276/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0680\n",
      "Epoch 277/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0678\n",
      "Epoch 278/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0677\n",
      "Epoch 279/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0675\n",
      "Epoch 280/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0673\n",
      "Epoch 281/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0671\n",
      "Epoch 282/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0670\n",
      "Epoch 283/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0668\n",
      "Epoch 284/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0666\n",
      "Epoch 285/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0664\n",
      "Epoch 286/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0663\n",
      "Epoch 287/500\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.4515 - loss: 1.0661\n",
      "Epoch 288/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0659\n",
      "Epoch 289/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0657\n",
      "Epoch 290/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0655\n",
      "Epoch 291/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0654\n",
      "Epoch 292/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0652\n",
      "Epoch 293/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0650\n",
      "Epoch 294/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0648\n",
      "Epoch 295/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0646\n",
      "Epoch 296/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0645\n",
      "Epoch 297/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0643\n",
      "Epoch 298/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0641\n",
      "Epoch 299/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.4515 - loss: 1.0639\n",
      "Epoch 300/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0637\n",
      "Epoch 301/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0636\n",
      "Epoch 302/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0634\n",
      "Epoch 303/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0632\n",
      "Epoch 304/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0630\n",
      "Epoch 305/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0628\n",
      "Epoch 306/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0626\n",
      "Epoch 307/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0624\n",
      "Epoch 308/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0622\n",
      "Epoch 309/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0620\n",
      "Epoch 310/500\n",
      "1/1 - 0s - 27ms/step - accuracy: 0.4515 - loss: 1.0618\n",
      "Epoch 311/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0616\n",
      "Epoch 312/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0614\n",
      "Epoch 313/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0612\n",
      "Epoch 314/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0610\n",
      "Epoch 315/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0608\n",
      "Epoch 316/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0606\n",
      "Epoch 317/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0604\n",
      "Epoch 318/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0602\n",
      "Epoch 319/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.4515 - loss: 1.0600\n",
      "Epoch 320/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0598\n",
      "Epoch 321/500\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.4515 - loss: 1.0596\n",
      "Epoch 322/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0594\n",
      "Epoch 323/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0592\n",
      "Epoch 324/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0590\n",
      "Epoch 325/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0588\n",
      "Epoch 326/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0586\n",
      "Epoch 327/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0584\n",
      "Epoch 328/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0582\n",
      "Epoch 329/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0580\n",
      "Epoch 330/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0578\n",
      "Epoch 331/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0576\n",
      "Epoch 332/500\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.4515 - loss: 1.0575\n",
      "Epoch 333/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0573\n",
      "Epoch 334/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0571\n",
      "Epoch 335/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0569\n",
      "Epoch 336/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0567\n",
      "Epoch 337/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0565\n",
      "Epoch 338/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0563\n",
      "Epoch 339/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0561\n",
      "Epoch 340/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0559\n",
      "Epoch 341/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0557\n",
      "Epoch 342/500\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.4515 - loss: 1.0555\n",
      "Epoch 343/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0554\n",
      "Epoch 344/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0552\n",
      "Epoch 345/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0550\n",
      "Epoch 346/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0548\n",
      "Epoch 347/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0546\n",
      "Epoch 348/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0545\n",
      "Epoch 349/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0543\n",
      "Epoch 350/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0541\n",
      "Epoch 351/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0539\n",
      "Epoch 352/500\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.4515 - loss: 1.0538\n",
      "Epoch 353/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4515 - loss: 1.0537\n",
      "Epoch 354/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0535\n",
      "Epoch 355/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0534\n",
      "Epoch 356/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0532\n",
      "Epoch 357/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0530\n",
      "Epoch 358/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0529\n",
      "Epoch 359/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0527\n",
      "Epoch 360/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.4515 - loss: 1.0526\n",
      "Epoch 361/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0524\n",
      "Epoch 362/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0523\n",
      "Epoch 363/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0521\n",
      "Epoch 364/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0520\n",
      "Epoch 365/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0518\n",
      "Epoch 366/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0517\n",
      "Epoch 367/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.4515 - loss: 1.0515\n",
      "Epoch 368/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0514\n",
      "Epoch 369/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0512\n",
      "Epoch 370/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4515 - loss: 1.0511\n",
      "Epoch 371/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0509\n",
      "Epoch 372/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0508\n",
      "Epoch 373/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0506\n",
      "Epoch 374/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0505\n",
      "Epoch 375/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0504\n",
      "Epoch 376/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0502\n",
      "Epoch 377/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0501\n",
      "Epoch 378/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0499\n",
      "Epoch 379/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0498\n",
      "Epoch 380/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0497\n",
      "Epoch 381/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0495\n",
      "Epoch 382/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0494\n",
      "Epoch 383/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0492\n",
      "Epoch 384/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0491\n",
      "Epoch 385/500\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.4515 - loss: 1.0490\n",
      "Epoch 386/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0488\n",
      "Epoch 387/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0487\n",
      "Epoch 388/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0485\n",
      "Epoch 389/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0484\n",
      "Epoch 390/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0483\n",
      "Epoch 391/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0481\n",
      "Epoch 392/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0480\n",
      "Epoch 393/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0479\n",
      "Epoch 394/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0477\n",
      "Epoch 395/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0476\n",
      "Epoch 396/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0475\n",
      "Epoch 397/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0473\n",
      "Epoch 398/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0472\n",
      "Epoch 399/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0471\n",
      "Epoch 400/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0469\n",
      "Epoch 401/500\n",
      "1/1 - 0s - 23ms/step - accuracy: 0.4515 - loss: 1.0468\n",
      "Epoch 402/500\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.4515 - loss: 1.0467\n",
      "Epoch 403/500\n",
      "1/1 - 0s - 24ms/step - accuracy: 0.4515 - loss: 1.0466\n",
      "Epoch 404/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4515 - loss: 1.0464\n",
      "Epoch 405/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0463\n",
      "Epoch 406/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0462\n",
      "Epoch 407/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0460\n",
      "Epoch 408/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0459\n",
      "Epoch 409/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0458\n",
      "Epoch 410/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0455\n",
      "Epoch 411/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0452\n",
      "Epoch 412/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4515 - loss: 1.0449\n",
      "Epoch 413/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0446\n",
      "Epoch 414/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0442\n",
      "Epoch 415/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4515 - loss: 1.0438\n",
      "Epoch 416/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0433\n",
      "Epoch 417/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0429\n",
      "Epoch 418/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.4515 - loss: 1.0424\n",
      "Epoch 419/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4515 - loss: 1.0420\n",
      "Epoch 420/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4515 - loss: 1.0415\n",
      "Epoch 421/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0410\n",
      "Epoch 422/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4599 - loss: 1.0405\n",
      "Epoch 423/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0400\n",
      "Epoch 424/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4599 - loss: 1.0395\n",
      "Epoch 425/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0390\n",
      "Epoch 426/500\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.4599 - loss: 1.0386\n",
      "Epoch 427/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4599 - loss: 1.0381\n",
      "Epoch 428/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0376\n",
      "Epoch 429/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0371\n",
      "Epoch 430/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4599 - loss: 1.0366\n",
      "Epoch 431/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4599 - loss: 1.0361\n",
      "Epoch 432/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.4599 - loss: 1.0356\n",
      "Epoch 433/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4599 - loss: 1.0351\n",
      "Epoch 434/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.4599 - loss: 1.0346\n",
      "Epoch 435/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.4599 - loss: 1.0341\n",
      "Epoch 436/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0336\n",
      "Epoch 437/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0331\n",
      "Epoch 438/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0326\n",
      "Epoch 439/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0322\n",
      "Epoch 440/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0317\n",
      "Epoch 441/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4599 - loss: 1.0312\n",
      "Epoch 442/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.4599 - loss: 1.0307\n",
      "Epoch 443/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4768 - loss: 1.0302\n",
      "Epoch 444/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4768 - loss: 1.0298\n",
      "Epoch 445/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4768 - loss: 1.0293\n",
      "Epoch 446/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.4768 - loss: 1.0288\n",
      "Epoch 447/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5063 - loss: 1.0283\n",
      "Epoch 448/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5063 - loss: 1.0279\n",
      "Epoch 449/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5063 - loss: 1.0274\n",
      "Epoch 450/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.5063 - loss: 1.0269\n",
      "Epoch 451/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5063 - loss: 1.0265\n",
      "Epoch 452/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5063 - loss: 1.0260\n",
      "Epoch 453/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5063 - loss: 1.0255\n",
      "Epoch 454/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5063 - loss: 1.0251\n",
      "Epoch 455/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5063 - loss: 1.0246\n",
      "Epoch 456/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5063 - loss: 1.0241\n",
      "Epoch 457/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5063 - loss: 1.0237\n",
      "Epoch 458/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5063 - loss: 1.0232\n",
      "Epoch 459/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5063 - loss: 1.0228\n",
      "Epoch 460/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5063 - loss: 1.0223\n",
      "Epoch 461/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0219\n",
      "Epoch 462/500\n",
      "1/1 - 0s - 15ms/step - accuracy: 0.5359 - loss: 1.0214\n",
      "Epoch 463/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0210\n",
      "Epoch 464/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0205\n",
      "Epoch 465/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5359 - loss: 1.0201\n",
      "Epoch 466/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.5359 - loss: 1.0196\n",
      "Epoch 467/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5359 - loss: 1.0192\n",
      "Epoch 468/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0187\n",
      "Epoch 469/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0183\n",
      "Epoch 470/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5359 - loss: 1.0179\n",
      "Epoch 471/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0174\n",
      "Epoch 472/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5359 - loss: 1.0170\n",
      "Epoch 473/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0165\n",
      "Epoch 474/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0161\n",
      "Epoch 475/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0157\n",
      "Epoch 476/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5359 - loss: 1.0152\n",
      "Epoch 477/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0148\n",
      "Epoch 478/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0144\n",
      "Epoch 479/500\n",
      "1/1 - 0s - 21ms/step - accuracy: 0.5359 - loss: 1.0139\n",
      "Epoch 480/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5359 - loss: 1.0135\n",
      "Epoch 481/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0131\n",
      "Epoch 482/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0127\n",
      "Epoch 483/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0123\n",
      "Epoch 484/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0118\n",
      "Epoch 485/500\n",
      "1/1 - 0s - 22ms/step - accuracy: 0.5359 - loss: 1.0114\n",
      "Epoch 486/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5359 - loss: 1.0110\n",
      "Epoch 487/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5359 - loss: 1.0106\n",
      "Epoch 488/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0102\n",
      "Epoch 489/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5359 - loss: 1.0098\n",
      "Epoch 490/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0094\n",
      "Epoch 491/500\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5359 - loss: 1.0089\n",
      "Epoch 492/500\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.5359 - loss: 1.0085\n",
      "Epoch 493/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5359 - loss: 1.0081\n",
      "Epoch 494/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0077\n",
      "Epoch 495/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0073\n",
      "Epoch 496/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0069\n",
      "Epoch 497/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0065\n",
      "Epoch 498/500\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5359 - loss: 1.0061\n",
      "Epoch 499/500\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.5359 - loss: 1.0057\n",
      "Epoch 500/500\n",
      "1/1 - 0s - 19ms/step - accuracy: 0.5359 - loss: 1.0053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4667 - loss: 1.0570\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "tf.Tensor(\n",
      "[[ 0 11  7]\n",
      " [ 0 24  0]\n",
      " [ 0 14  4]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Begin NN training\n",
    "NUMBER_OF_ATTRS = df_train.shape[1]\n",
    "\n",
    "# Convert int values to TF expect values (float)\n",
    "df_train = np.asarray(df_train).astype(np.float32)\n",
    "df_test = np.asarray(df_test).astype(np.float32)\n",
    "# Converts pandas dataframe to tensorflow object\n",
    "df_train = tf.convert_to_tensor(df_train)\n",
    "# Normalize the data\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "normalizer.adapt(df_train)\n",
    "\n",
    "label_train = np.asarray(label_train).astype(np.float32)\n",
    "#normalizer.adapt(numeric_features_test)\n",
    "\n",
    "# Execute Trainning \n",
    "print('Starting training for',number_of_attributes,'attributes')\n",
    "model = get_basic_model()\n",
    "model.fit(df_train, label_train, epochs=EPOCHS, verbose=2, batch_size=BATCH_SIZE)\n",
    "\n",
    "# and Testing\n",
    "test_loss, one_test_acc =  model.evaluate(df_test,  label_test, verbose=1, batch_size=BATCH_SIZE)\n",
    "tf_predictions_probabilities = model.predict(df_test)\n",
    "\n",
    "#Crate Confusion Matrix for better understanding of results\n",
    "tf_predictions = []\n",
    "for i,x in enumerate(tf_predictions_probabilities):\n",
    "  #print(\"i:\",i,\"x_max:\",x.max(),\"x:\",x)\n",
    "  j_max = x.argmax()\n",
    "  tf_predictions.append(j_max)\n",
    "\n",
    "conf_m = tf.math.confusion_matrix(label_test,tf_predictions)\n",
    "print(conf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ normalization (\u001b[38;5;33mNormalization\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   â”‚               \u001b[38;5;34m7\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   â”‚              \u001b[38;5;34m12\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   â”‚              \u001b[38;5;34m12\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (332.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81\u001b[0m (332.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> (96.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24\u001b[0m (96.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> (32.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7\u001b[0m (32.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> (204.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m50\u001b[0m (204.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input -> Normalization Layer bias:\n",
      " [0.6153218  0.56095093 0.51726073]\n",
      "\n",
      "Input -> Normalization Layer weights:\n",
      " [-0.14767933 -0.1308017  -0.21940929]\n",
      "\n",
      "Normalization -> Hidden Layer bias:\n",
      " [-0.2804896  -0.08071144  0.01189113]\n",
      "\n",
      "Normalization -> Hidden Layer weights:\n",
      " [[ 0.38790786 -0.08814368 -0.41493565]\n",
      " [-0.26708868  0.71702576  0.35362825]\n",
      " [-0.27892858 -0.09141283 -0.86742264]]\n",
      "\n",
      "Hidden -> Output Layer bias:\n",
      " [-0.26221707  0.27602214 -0.39916393]\n",
      "\n",
      "Hidden -> Output Layer weights:\n",
      " [[ 0.6986372   0.67080164 -0.5358617 ]\n",
      " [-0.40344965 -1.1579047   0.33075055]\n",
      " [-0.01508353 -0.17391126 -0.12919842]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model info\n",
    "model.summary()\n",
    "norm_layer_weights = model.layers[0].get_weights()[0] #weight\n",
    "norm_layer_biases  = model.layers[0].get_weights()[1] #bias\n",
    "hidden_layer_weights = model.layers[1].get_weights()[0] #weight\n",
    "hidden_layer_biases  = model.layers[1].get_weights()[1] #bias\n",
    "out_layer_weights = model.layers[2].get_weights()[0] #weight\n",
    "out_layer_biases  = model.layers[2].get_weights()[1] #bias\n",
    "print('\\nInput -> Normalization Layer bias:\\n',norm_layer_biases)\n",
    "print('\\nInput -> Normalization Layer weights:\\n',norm_layer_weights)\n",
    "print('\\nNormalization -> Hidden Layer bias:\\n',hidden_layer_biases)\n",
    "print('\\nNormalization -> Hidden Layer weights:\\n',hidden_layer_weights)\n",
    "print('\\nHidden -> Output Layer bias:\\n',out_layer_biases)\n",
    "print('\\nHidden -> Output Layer weights:\\n',out_layer_weights,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1. -1.  1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 1. -1.  1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [-1.  1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 1. -1.  1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  0.]\n",
      " [-1. -1. -1.]\n",
      " [-1.  0. -1.]\n",
      " [-1.  0. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [-1. -1. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [-1.  0. -1.]\n",
      " [-1. -1. -1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  0.  0.]\n",
      " [-1.  0. -1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 1.  1.  0.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  0.  1.]\n",
      " [-1. -1. -1.]\n",
      " [-1.  1. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 1.  0.  1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [-1.  0. -1.]\n",
      " [ 0.  0.  0.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [-1.  1. -1.]\n",
      " [ 0.  0.  1.]\n",
      " [-1.  0. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24000341 -0.2331785  -0.        ]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [-0.24000341  0.2331785  -0.42417541]\n",
      " [-0.         -0.         -0.        ]\n",
      " [-0.24000341 -0.         -0.        ]\n",
      " [-0.         -0.         -0.        ]\n",
      " [-0.24000341  0.2331785  -0.42417541]\n",
      " [-0.          0.2331785  -0.        ]\n",
      " [-0.         -0.         -0.        ]\n",
      " [ 0.24000341 -0.2331785   0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [-0.24000341 -0.         -0.        ]\n",
      " [-0.          0.2331785  -0.        ]\n",
      " [-0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.        ]\n",
      " [-0.24000341  0.2331785  -0.42417541]\n",
      " [-0.          0.2331785  -0.        ]\n",
      " [-0.         -0.         -0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [-0.24000341 -0.         -0.42417541]\n",
      " [-0.         -0.         -0.42417541]\n",
      " [-0.         -0.         -0.        ]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [ 0.24000341 -0.          0.42417541]\n",
      " [ 0.24000341 -0.          0.42417541]\n",
      " [-0.         -0.2331785  -0.        ]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [-0.         -0.         -0.        ]\n",
      " [ 0.24000341 -0.          0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [-0.24000341 -0.         -0.        ]\n",
      " [ 0.24000341 -0.          0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [-0.24000341 -0.         -0.42417541]\n",
      " [-0.         -0.         -0.        ]\n",
      " [-0.24000341 -0.2331785  -0.        ]\n",
      " [ 0.24000341 -0.2331785   0.42417541]\n",
      " [-0.24000341 -0.2331785  -0.42417541]\n",
      " [ 0.24000341 -0.2331785   0.42417541]\n",
      " [-0.24000341 -0.         -0.42417541]\n",
      " [ 0.24000341  0.2331785   0.42417541]\n",
      " [ 0.24000341 -0.2331785   0.42417541]\n",
      " [-0.          0.2331785  -0.        ]\n",
      " [-0.24000341 -0.         -0.42417541]\n",
      " [-0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.42417541]\n",
      " [-0.         -0.         -0.42417541]\n",
      " [ 0.24000341 -0.          0.42417541]\n",
      " [-0.         -0.         -0.        ]\n",
      " [ 0.24000341 -0.2331785   0.42417541]\n",
      " [-0.24000341 -0.2331785  -0.42417541]\n",
      " [-0.24000341 -0.         -0.        ]\n",
      " [ 0.24000341 -0.2331785   0.42417541]\n",
      " [-0.         -0.         -0.42417541]\n",
      " [ 0.24000341 -0.          0.42417541]\n",
      " [-0.          0.2331785  -0.        ]\n",
      " [-0.          0.2331785  -0.        ]\n",
      " [-0.         -0.         -0.42417541]]\n"
     ]
    }
   ],
   "source": [
    "# LUT table implementation: Internal Value Simulator\n",
    "\n",
    "input_data = [-1, 0, 1] # all n possibilities a the unit type can measure\n",
    "norm_data = np.zeros(input_data.shape)\n",
    "h1_data = np.zeros(input_data.shape)\n",
    "out_data = np.zeros(input_data.shape)\n",
    "\n",
    "# manual norm layer implementation\n",
    "for row in range(input_data.shape[0]):\n",
    "    for column in range(input_data.shape[1]):\n",
    "        #print(input_data[row][column])\n",
    "        norm_data[row][column] = (input_data[row][column] * norm_layer_weights[column]) / norm_layer_biases[column]\n",
    "print(norm_data)\n",
    "\n",
    "# manual h1 layer implementation\n",
    "for row in range(norm_data.shape[0]):\n",
    "    for column in range(norm_data.shape[1]):\n",
    "        #print(input_data[row][column])\n",
    "        h1_data[row][column] = \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1716259966440,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "hqqrljwkNZ_p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-11-2024-14-41-59\n"
     ]
    }
   ],
   "source": [
    "# Date for report file\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "print(dt_string)\n",
    "# Report file content\n",
    "report = {\n",
    "    \"datetime\": dt_string,\n",
    "    \"number_of_attributes\": number_of_attributes,\n",
    "    \"hidden_layer_nodes\": hidden_layer_nodes,\n",
    "    \"output_layer_nodes\": output_layer_nodes,\n",
    "    \"accuracy_test\": one_test_acc,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS\n",
    "    #\"number_of_samples\": number_of_samples,\n",
    "    #\"df_number\": df_number\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5378,
     "status": "ok",
     "timestamp": 1716259977049,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "DL5sxqffj2co"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\NN-P4\\tf-params-reports\n",
      "C:\\NN-P4\\tf-models\n"
     ]
    }
   ],
   "source": [
    "#TO DO: use save_models instead of save_weights\n",
    "\n",
    "# Model parameters json file generation, create file with date-time string to prevent unwated/accidental overwrites\n",
    "os.chdir('../tf-params-reports/')\n",
    "print(os.getcwd())\n",
    "\n",
    "title_parameters_save = f\"nn-nprint-{use_case}-model-parameters-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.json\"\n",
    "with open(title_parameters_save, \"w\") as f:\n",
    "  json.dump(report, f)\n",
    "\n",
    "title_parameters_save = f\"nn-nprint-{use_case}-model-parameters-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}-{dt_string}.json\"\n",
    "with open(title_parameters_save, \"w\") as f:\n",
    "  json.dump(report, f)\n",
    "\n",
    "# Model file with weights and other params\n",
    "os.chdir('../tf-models/') \n",
    "print(os.getcwd())\n",
    "\n",
    "title_model_save = f'nn-nprint-{use_case}-model-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.keras'\n",
    "model.save(title_model_save)\n",
    "\n",
    "# Model weights file generation\n",
    "# os.chdir('../tf-model-weights/')\n",
    "# print(os.getcwd())\n",
    "\n",
    "# title_model_save = f'nn-nprint-model-weights-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.weights.h5'\n",
    "# model.save_weights(title_model_save) # Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "\n",
    "# title_model_save = f'nn-nprint-model-weights-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}-{dt_string}.weights.h5'\n",
    "# model.save_weights(title_model_save) # Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "    \n",
    "# model.load_weights(f'nn-nprint-app-iden-model-weights-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.802741289138794\n"
     ]
    }
   ],
   "source": [
    "# Save timestamp\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Acervo - comandos Ãºteis os python\n",
    "# %pwd\n",
    "# os.chdir(C:\\NN-P4\\nn-reports)\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "# os.listdir()\n",
    "# os.chdir('../nn-reports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 1108,
     "status": "error",
     "timestamp": 1716259692331,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "OsFlOvQqF-KK",
    "outputId": "7f2b6ca8-0e18-477c-c605-075a9a5eeb1a"
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/X.pkl')\n",
    "# df_test = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/X_val.pkl')\n",
    "# label_train = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/y.pkl')\n",
    "# label_test = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/y_val.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIH1M4SDzT/02evItuJvc2",
   "provenance": [
    {
     "file_id": "1N0tN69OVtNS4K7h67xdyUtJ0_hWbDa9x",
     "timestamp": 1701094766071
    },
    {
     "file_id": "18-qqwOnAL89_m5Lb45uZ40u1ut46iuIU",
     "timestamp": 1690808958392
    },
    {
     "file_id": "19JxEc2VYTW6pRVyhOmnsRVPvksE5gBBN",
     "timestamp": 1661778258249
    },
    {
     "file_id": "1u0E4CFsBf4k62yi38gfqB4HlagC-Tfhc",
     "timestamp": 1661541388425
    },
    {
     "file_id": "1Cpg4jNgwyPiT4AGenVm1xCQgBrzxHhCT",
     "timestamp": 1643821363627
    },
    {
     "file_id": "1k-uty64gq4zwMYT-FFDYnhQ-9Z5bXvQ-",
     "timestamp": 1642608790480
    },
    {
     "file_id": "1eXxWzQSIUjunkjCGopzkFpuoB42a7YbS",
     "timestamp": 1642604110588
    },
    {
     "file_id": "1Y0hheLUxBgA_oy3QG9nY0JRieWhjt4BM",
     "timestamp": 1639758139710
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
