{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32174,
     "status": "ok",
     "timestamp": 1716259511383,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "93XXr2GHiBqA",
    "outputId": "426a70a0-e654-4846-dbd0-850c3cc8e0e2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0-dev20240611\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8SEnBPkJBjY"
   },
   "source": [
    "### Specify here the NN topology and the dataframe to be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1716259684236,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "CT-15-PmiHZn"
   },
   "outputs": [],
   "source": [
    "#specify the NN topology here:\n",
    "#input_layer_nodes = number_of_attributes\n",
    "number_of_attributes = 16\n",
    "hidden_layer_nodes = 32\n",
    "output_layer_nodes = 2\n",
    "\n",
    "\n",
    "use_case = \"netml-iot\"\n",
    "dataset_folder = f\"../datasets/nprint-raw/{use_case}/\"\n",
    "features_rankings = f\"../datasets/nprint-raw/{use_case}/feature-importance.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d35dDblII_J9"
   },
   "source": [
    "###Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1716259688443,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "tj2cFHLXkoXh"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 500\n",
    "\n",
    "def get_basic_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(hidden_layer_nodes, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_layer_nodes)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaiUaBAuI6HD"
   },
   "source": [
    "###Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2838,
     "status": "ok",
     "timestamp": 1716259736242,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "NLYaSSiIhrgz"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{dataset_folder}X.csv')\n",
    "df_test = pd.read_csv(f'{dataset_folder}X_val.csv')\n",
    "label_train = pd.read_csv(f'{dataset_folder}y.csv')\n",
    "label_test = pd.read_csv(f'{dataset_folder}y_val.csv')\n",
    "\n",
    "df_train.drop('pcap', axis=1, inplace=True)\n",
    "df_test.drop('pcap', axis=1, inplace=True)\n",
    "label_train.drop('pcap', axis=1, inplace=True)\n",
    "label_test.drop('pcap', axis=1, inplace=True)\n",
    "label_train.rename(columns={'0': 'label'}, inplace=True)\n",
    "label_test.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "# display(df_train)\n",
    "# display(df_test)\n",
    "# display(label_train)\n",
    "# display(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1716259749230,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "bHgpzuUgWT0J"
   },
   "outputs": [],
   "source": [
    "#select a sub-dataframe with only the top attrs rate by the AUTOGLUON feature importance algorithm\n",
    "#load the file with the rankings\n",
    "features_rankings_df = pd.read_csv(features_rankings)\n",
    "features_rankings_df.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "#make a list with only the best features\n",
    "feature_list = features_rankings_df['Unnamed: 0'].tolist()\n",
    "feature_list = feature_list[:number_of_attributes]\n",
    "# print(feature_list)\n",
    "\n",
    "#select a sub-dataframe with only the 32 top attrs rate by the AUTOGLUON feature importance algorithm\n",
    "df_train = df_train[feature_list]\n",
    "df_test = df_test[feature_list]\n",
    "# display(df_train)\n",
    "# display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3ngEN5GJTag"
   },
   "source": [
    "### NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29270,
     "status": "ok",
     "timestamp": 1716259884626,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "Axt9vLxMiO-6",
    "outputId": "9e385e82-fa0a-4943-c9c1-abaac3390b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 16 attributes\n",
      "Epoch 1/500\n",
      "24/24 - 0s - 21ms/step - accuracy: 0.7357 - loss: 0.5018\n",
      "Epoch 2/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.8634 - loss: 0.3451\n",
      "Epoch 3/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9495 - loss: 0.2507\n",
      "Epoch 4/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9895 - loss: 0.1868\n",
      "Epoch 5/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9901 - loss: 0.1429\n",
      "Epoch 6/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9900 - loss: 0.1120\n",
      "Epoch 7/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9907 - loss: 0.0897\n",
      "Epoch 8/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9912 - loss: 0.0737\n",
      "Epoch 9/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9913 - loss: 0.0619\n",
      "Epoch 10/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9917 - loss: 0.0530\n",
      "Epoch 11/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9921 - loss: 0.0464\n",
      "Epoch 12/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9920 - loss: 0.0412\n",
      "Epoch 13/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9925 - loss: 0.0372\n",
      "Epoch 14/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9938 - loss: 0.0341\n",
      "Epoch 15/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9927 - loss: 0.0311\n",
      "Epoch 16/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9940 - loss: 0.0286\n",
      "Epoch 17/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9952 - loss: 0.0266\n",
      "Epoch 18/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9948 - loss: 0.0249\n",
      "Epoch 19/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9950 - loss: 0.0235\n",
      "Epoch 20/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9961 - loss: 0.0222\n",
      "Epoch 21/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9957 - loss: 0.0210\n",
      "Epoch 22/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9962 - loss: 0.0199\n",
      "Epoch 23/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9962 - loss: 0.0190\n",
      "Epoch 24/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9962 - loss: 0.0183\n",
      "Epoch 25/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9966 - loss: 0.0174\n",
      "Epoch 26/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9966 - loss: 0.0168\n",
      "Epoch 27/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0161\n",
      "Epoch 28/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0155\n",
      "Epoch 29/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9966 - loss: 0.0151\n",
      "Epoch 30/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0145\n",
      "Epoch 31/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0139\n",
      "Epoch 32/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0135\n",
      "Epoch 33/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0132\n",
      "Epoch 34/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0127\n",
      "Epoch 35/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0123\n",
      "Epoch 36/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0120\n",
      "Epoch 37/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9969 - loss: 0.0117\n",
      "Epoch 38/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9969 - loss: 0.0114\n",
      "Epoch 39/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9967 - loss: 0.0111\n",
      "Epoch 40/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9970 - loss: 0.0109\n",
      "Epoch 41/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9968 - loss: 0.0106\n",
      "Epoch 42/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9970 - loss: 0.0103\n",
      "Epoch 43/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9976 - loss: 0.0101\n",
      "Epoch 44/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9974 - loss: 0.0098\n",
      "Epoch 45/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9977 - loss: 0.0095\n",
      "Epoch 46/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9977 - loss: 0.0093\n",
      "Epoch 47/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9982 - loss: 0.0090\n",
      "Epoch 48/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9980 - loss: 0.0089\n",
      "Epoch 49/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9979 - loss: 0.0088\n",
      "Epoch 50/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9983 - loss: 0.0085\n",
      "Epoch 51/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9983 - loss: 0.0083\n",
      "Epoch 52/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9982 - loss: 0.0081\n",
      "Epoch 53/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9982 - loss: 0.0078\n",
      "Epoch 54/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9986 - loss: 0.0077\n",
      "Epoch 55/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9986 - loss: 0.0075\n",
      "Epoch 56/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9985 - loss: 0.0074\n",
      "Epoch 57/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9986 - loss: 0.0073\n",
      "Epoch 58/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9987 - loss: 0.0071\n",
      "Epoch 59/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9986 - loss: 0.0069\n",
      "Epoch 60/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9987 - loss: 0.0069\n",
      "Epoch 61/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9987 - loss: 0.0066\n",
      "Epoch 62/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9987 - loss: 0.0066\n",
      "Epoch 63/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9986 - loss: 0.0065\n",
      "Epoch 64/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0063\n",
      "Epoch 65/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0062\n",
      "Epoch 66/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0061\n",
      "Epoch 67/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9987 - loss: 0.0060\n",
      "Epoch 68/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9987 - loss: 0.0059\n",
      "Epoch 69/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0058\n",
      "Epoch 70/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0057\n",
      "Epoch 71/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0056\n",
      "Epoch 72/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0055\n",
      "Epoch 73/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9987 - loss: 0.0055\n",
      "Epoch 74/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0054\n",
      "Epoch 75/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0052\n",
      "Epoch 76/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0052\n",
      "Epoch 77/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0051\n",
      "Epoch 78/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0050\n",
      "Epoch 79/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0049\n",
      "Epoch 80/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0048\n",
      "Epoch 81/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0047\n",
      "Epoch 82/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0047\n",
      "Epoch 83/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0046\n",
      "Epoch 84/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0045\n",
      "Epoch 85/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0044\n",
      "Epoch 86/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0044\n",
      "Epoch 87/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0044\n",
      "Epoch 88/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0044\n",
      "Epoch 89/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0043\n",
      "Epoch 90/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0041\n",
      "Epoch 91/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0041\n",
      "Epoch 92/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0040\n",
      "Epoch 93/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0040\n",
      "Epoch 94/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0039\n",
      "Epoch 95/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0040\n",
      "Epoch 96/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0038\n",
      "Epoch 97/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9988 - loss: 0.0038\n",
      "Epoch 98/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0038\n",
      "Epoch 99/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0037\n",
      "Epoch 100/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0036\n",
      "Epoch 101/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0036\n",
      "Epoch 102/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9990 - loss: 0.0036\n",
      "Epoch 103/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9990 - loss: 0.0036\n",
      "Epoch 104/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9989 - loss: 0.0037\n",
      "Epoch 105/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0034\n",
      "Epoch 106/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9990 - loss: 0.0035\n",
      "Epoch 107/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0033\n",
      "Epoch 108/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0033\n",
      "Epoch 109/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9991 - loss: 0.0032\n",
      "Epoch 110/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0033\n",
      "Epoch 111/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0032\n",
      "Epoch 112/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9990 - loss: 0.0032\n",
      "Epoch 113/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0031\n",
      "Epoch 114/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0030\n",
      "Epoch 115/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9991 - loss: 0.0031\n",
      "Epoch 116/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0030\n",
      "Epoch 117/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0030\n",
      "Epoch 118/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0032\n",
      "Epoch 119/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9993 - loss: 0.0030\n",
      "Epoch 120/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0030\n",
      "Epoch 121/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9993 - loss: 0.0029\n",
      "Epoch 122/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0028\n",
      "Epoch 123/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0028\n",
      "Epoch 124/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0028\n",
      "Epoch 125/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0028\n",
      "Epoch 126/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0027\n",
      "Epoch 127/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0027\n",
      "Epoch 128/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9992 - loss: 0.0027\n",
      "Epoch 129/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0027\n",
      "Epoch 130/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0027\n",
      "Epoch 131/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9993 - loss: 0.0026\n",
      "Epoch 132/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0027\n",
      "Epoch 133/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0026\n",
      "Epoch 134/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0027\n",
      "Epoch 135/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 136/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 137/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 138/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 139/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0024\n",
      "Epoch 140/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 141/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0024\n",
      "Epoch 142/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 143/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 144/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 145/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 146/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 147/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 148/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 149/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0022\n",
      "Epoch 150/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0022\n",
      "Epoch 151/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0022\n",
      "Epoch 152/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9994 - loss: 0.0022\n",
      "Epoch 153/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0022\n",
      "Epoch 154/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0022\n",
      "Epoch 155/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0021\n",
      "Epoch 156/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0021\n",
      "Epoch 157/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0021\n",
      "Epoch 158/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0021\n",
      "Epoch 159/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0021\n",
      "Epoch 160/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0021\n",
      "Epoch 161/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0020\n",
      "Epoch 162/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 163/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 164/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0020\n",
      "Epoch 165/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 166/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 167/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0020\n",
      "Epoch 168/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 169/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 170/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 171/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 172/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 173/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0019\n",
      "Epoch 174/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0019\n",
      "Epoch 175/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0018\n",
      "Epoch 176/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 177/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 178/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 179/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 180/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0018\n",
      "Epoch 181/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 182/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 183/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0017\n",
      "Epoch 184/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0017\n",
      "Epoch 185/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 186/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9996 - loss: 0.0018\n",
      "Epoch 187/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 188/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 189/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 190/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 191/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0017\n",
      "Epoch 192/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 193/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 194/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 195/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 196/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 197/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 198/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 199/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 200/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 201/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 202/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 203/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 204/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 205/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 206/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 207/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 208/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 209/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 210/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 211/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 212/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 213/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 214/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 215/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 216/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 217/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 218/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 219/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 220/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 221/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 222/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 223/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 224/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 225/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 226/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 227/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 228/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 229/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 230/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 231/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 232/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 233/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 234/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 235/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 236/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 237/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 238/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 239/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 240/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 241/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0014\n",
      "Epoch 242/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 243/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 244/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 245/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 246/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 247/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 248/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 249/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 250/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 251/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 252/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 253/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 254/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 255/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 256/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 257/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 258/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 259/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 260/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 261/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 262/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 263/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 264/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 265/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 266/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0013\n",
      "Epoch 267/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 268/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 269/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 270/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 271/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 272/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 273/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 274/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 275/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 276/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0012\n",
      "Epoch 277/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 278/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 279/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 280/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 281/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 282/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 283/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 284/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 285/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 286/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 287/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 288/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0013\n",
      "Epoch 289/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0012\n",
      "Epoch 290/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 291/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 292/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 293/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 294/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 295/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 296/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 297/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 298/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 299/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 300/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 301/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 302/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 303/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 304/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 305/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0010\n",
      "Epoch 306/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 307/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 308/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 309/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 310/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 311/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 312/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 313/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 314/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 315/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 316/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0012\n",
      "Epoch 317/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 318/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 319/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 320/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9486e-04\n",
      "Epoch 321/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 322/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6429e-04\n",
      "Epoch 323/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 324/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 325/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8577e-04\n",
      "Epoch 326/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9629e-04\n",
      "Epoch 327/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 328/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5874e-04\n",
      "Epoch 329/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8675e-04\n",
      "Epoch 330/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 331/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 332/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 333/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 334/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2352e-04\n",
      "Epoch 335/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 336/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9026e-04\n",
      "Epoch 337/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8017e-04\n",
      "Epoch 338/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 9.6909e-04\n",
      "Epoch 339/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 340/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 341/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 342/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 343/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5784e-04\n",
      "Epoch 344/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8548e-04\n",
      "Epoch 345/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7463e-04\n",
      "Epoch 346/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 347/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 348/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 349/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8287e-04\n",
      "Epoch 350/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5886e-04\n",
      "Epoch 351/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4479e-04\n",
      "Epoch 352/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9995 - loss: 0.0012\n",
      "Epoch 353/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9670e-04\n",
      "Epoch 354/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4338e-04\n",
      "Epoch 355/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6208e-04\n",
      "Epoch 356/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8993e-04\n",
      "Epoch 357/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9737e-04\n",
      "Epoch 358/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1980e-04\n",
      "Epoch 359/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5102e-04\n",
      "Epoch 360/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4466e-04\n",
      "Epoch 361/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 8.9725e-04\n",
      "Epoch 362/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6399e-04\n",
      "Epoch 363/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4587e-04\n",
      "Epoch 364/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5940e-04\n",
      "Epoch 365/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9323e-04\n",
      "Epoch 366/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0336e-04\n",
      "Epoch 367/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5893e-04\n",
      "Epoch 368/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 369/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 370/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7626e-04\n",
      "Epoch 371/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7745e-04\n",
      "Epoch 372/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4013e-04\n",
      "Epoch 373/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 374/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5764e-04\n",
      "Epoch 375/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0623e-04\n",
      "Epoch 376/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2465e-04\n",
      "Epoch 377/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0084e-04\n",
      "Epoch 378/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1364e-04\n",
      "Epoch 379/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6349e-04\n",
      "Epoch 380/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6668e-04\n",
      "Epoch 381/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9718e-04\n",
      "Epoch 382/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.9329e-04\n",
      "Epoch 383/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 9.6820e-04\n",
      "Epoch 384/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8943e-04\n",
      "Epoch 385/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.5953e-04\n",
      "Epoch 386/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8666e-04\n",
      "Epoch 387/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7314e-04\n",
      "Epoch 388/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4088e-04\n",
      "Epoch 389/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4076e-04\n",
      "Epoch 390/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 391/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 392/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5417e-04\n",
      "Epoch 393/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8980e-04\n",
      "Epoch 394/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1017e-04\n",
      "Epoch 395/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2218e-04\n",
      "Epoch 396/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2111e-04\n",
      "Epoch 397/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.6690e-04\n",
      "Epoch 398/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9276e-04\n",
      "Epoch 399/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1356e-04\n",
      "Epoch 400/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8328e-04\n",
      "Epoch 401/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8784e-04\n",
      "Epoch 402/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1089e-04\n",
      "Epoch 403/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7205e-04\n",
      "Epoch 404/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 8.7979e-04\n",
      "Epoch 405/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0271e-04\n",
      "Epoch 406/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5391e-04\n",
      "Epoch 407/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4499e-04\n",
      "Epoch 408/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5090e-04\n",
      "Epoch 409/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0162e-04\n",
      "Epoch 410/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9855e-04\n",
      "Epoch 411/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8561e-04\n",
      "Epoch 412/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.6477e-04\n",
      "Epoch 413/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0798e-04\n",
      "Epoch 414/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6909e-04\n",
      "Epoch 415/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.3709e-04\n",
      "Epoch 416/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.3110e-04\n",
      "Epoch 417/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8269e-04\n",
      "Epoch 418/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6324e-04\n",
      "Epoch 419/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9892e-04\n",
      "Epoch 420/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9901e-04\n",
      "Epoch 421/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.6538e-04\n",
      "Epoch 422/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2744e-04\n",
      "Epoch 423/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.4781e-04\n",
      "Epoch 424/500\n",
      "24/24 - 0s - 3ms/step - accuracy: 0.9998 - loss: 8.3509e-04\n",
      "Epoch 425/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9793e-04\n",
      "Epoch 426/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0358e-04\n",
      "Epoch 427/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.6955e-04\n",
      "Epoch 428/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9517e-04\n",
      "Epoch 429/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.4241e-04\n",
      "Epoch 430/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0858e-04\n",
      "Epoch 431/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7993e-04\n",
      "Epoch 432/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9834e-04\n",
      "Epoch 433/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8375e-04\n",
      "Epoch 434/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.3799e-04\n",
      "Epoch 435/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8365e-04\n",
      "Epoch 436/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0289e-04\n",
      "Epoch 437/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5956e-04\n",
      "Epoch 438/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8050e-04\n",
      "Epoch 439/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2070e-04\n",
      "Epoch 440/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0019e-04\n",
      "Epoch 441/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.6310e-04\n",
      "Epoch 442/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1584e-04\n",
      "Epoch 443/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 444/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7934e-04\n",
      "Epoch 445/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0926e-04\n",
      "Epoch 446/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.0646e-04\n",
      "Epoch 447/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7811e-04\n",
      "Epoch 448/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.6047e-04\n",
      "Epoch 449/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8526e-04\n",
      "Epoch 450/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.2628e-04\n",
      "Epoch 451/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9529e-04\n",
      "Epoch 452/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0637e-04\n",
      "Epoch 453/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7610e-04\n",
      "Epoch 454/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.3627e-04\n",
      "Epoch 455/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.1504e-04\n",
      "Epoch 456/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1734e-04\n",
      "Epoch 457/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7129e-04\n",
      "Epoch 458/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.7957e-04\n",
      "Epoch 459/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5161e-04\n",
      "Epoch 460/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.2060e-04\n",
      "Epoch 461/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 8.6513e-04\n",
      "Epoch 462/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7693e-04\n",
      "Epoch 463/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1529e-04\n",
      "Epoch 464/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.8355e-04\n",
      "Epoch 465/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5009e-04\n",
      "Epoch 466/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0662e-04\n",
      "Epoch 467/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 0.0010\n",
      "Epoch 468/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.3957e-04\n",
      "Epoch 469/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7507e-04\n",
      "Epoch 470/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.3300e-04\n",
      "Epoch 471/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 8.6017e-04\n",
      "Epoch 472/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.4011e-04\n",
      "Epoch 473/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.0401e-04\n",
      "Epoch 474/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.5547e-04\n",
      "Epoch 475/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.3674e-04\n",
      "Epoch 476/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.0305e-04\n",
      "Epoch 477/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.4635e-04\n",
      "Epoch 478/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 8.5714e-04\n",
      "Epoch 479/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7451e-04\n",
      "Epoch 480/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9163e-04\n",
      "Epoch 481/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.3914e-04\n",
      "Epoch 482/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 9.1628e-04\n",
      "Epoch 483/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.3579e-04\n",
      "Epoch 484/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.2064e-04\n",
      "Epoch 485/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8190e-04\n",
      "Epoch 486/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.2140e-04\n",
      "Epoch 487/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.2366e-04\n",
      "Epoch 488/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.0822e-04\n",
      "Epoch 489/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.6552e-04\n",
      "Epoch 490/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8636e-04\n",
      "Epoch 491/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.8578e-04\n",
      "Epoch 492/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 7.8869e-04\n",
      "Epoch 493/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9860e-04\n",
      "Epoch 494/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7760e-04\n",
      "Epoch 495/500\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9998 - loss: 9.7180e-04\n",
      "Epoch 496/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.4083e-04\n",
      "Epoch 497/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.7765e-04\n",
      "Epoch 498/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.9517e-04\n",
      "Epoch 499/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.3391e-04\n",
      "Epoch 500/500\n",
      "24/24 - 0s - 1ms/step - accuracy: 0.9998 - loss: 8.2460e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2782e-04 \n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step\n",
      "tf.Tensor(\n",
      "[[341   0]\n",
      " [  0 991]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Begin NN training\n",
    "NUMBER_OF_ATTRS = df_train.shape[1]\n",
    "\n",
    "# Convert int values to TF expect values (float)\n",
    "df_train = np.asarray(df_train).astype(np.float32)\n",
    "df_test = np.asarray(df_test).astype(np.float32)\n",
    "# Converts pandas dataframe to tensorflow object\n",
    "df_train = tf.convert_to_tensor(df_train)\n",
    "# Normalize the data\n",
    "normalizer = tf.keras.layers.Normalization()\n",
    "normalizer.adapt(df_train)\n",
    "#normalizer.adapt(numeric_features_test)\n",
    "\n",
    "# Execute Trainning \n",
    "print('Starting training for',number_of_attributes,'attributes')\n",
    "model = get_basic_model()\n",
    "model.fit(df_train, label_train, epochs=EPOCHS, verbose=2, batch_size=BATCH_SIZE)\n",
    "\n",
    "# and Testing\n",
    "test_loss, one_test_acc =  model.evaluate(df_test,  label_test, verbose=1, batch_size=BATCH_SIZE)\n",
    "tf_predictions_probabilities = model.predict(df_test)\n",
    "\n",
    "#Crate Confusion Matrix for better understanding of results\n",
    "tf_predictions = []\n",
    "for i,x in enumerate(tf_predictions_probabilities):\n",
    "  #print(\"i:\",i,\"x_max:\",x.max(),\"x:\",x)\n",
    "  j_max = x.argmax()\n",
    "  tf_predictions.append(j_max)\n",
    "\n",
    "conf_m = tf.math.confusion_matrix(label_test,tf_predictions)\n",
    "print(conf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m33\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,865</span> (7.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,865\u001b[0m (7.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> (2.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m610\u001b[0m (2.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> (136.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m33\u001b[0m (136.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,222</span> (4.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,222\u001b[0m (4.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input -> Normalization Layer bias:\n",
      " [0.26042014 0.2591248  0.06433415 0.05689694 0.26671037 0.5895072\n",
      " 0.03620648 0.26985016 0.0080265  0.1776892  0.68416846 0.9210642\n",
      " 0.40731376 0.4540065  0.36856326 0.25212252]\n",
      "\n",
      "Input -> Normalization Layer weights:\n",
      " [ 0.57587385  0.5840494   0.05072162  0.06056561 -0.15416701 -0.45499292\n",
      "  0.02043881 -0.60256946 -0.0080921   0.7689163  -0.3951781   0.19404355\n",
      " -0.27921915 -0.2487695  -0.7941103  -0.6105781 ]\n",
      "\n",
      "Normalization -> Hidden Layer bias:\n",
      " [ 0.16697688  0.11481686  0.31152403  0.09247332  0.03269651  0.3330602\n",
      " -0.1946107  -0.07160804 -0.03138632  0.20187598 -0.21255657  0.1747336\n",
      "  0.02342194  0.69106007  0.07127851 -0.03114577  0.16166943 -0.03466644\n",
      "  0.5816025  -0.03995842 -0.07570551  0.07546188 -0.10182013  0.11338563\n",
      "  0.32303998 -0.07530031 -0.01300398  0.16719915  0.67625046  0.1945209\n",
      " -0.18082404 -0.10174499]\n",
      "\n",
      "Normalization -> Hidden Layer weights:\n",
      " [[ 0.4242589   0.16685    -0.26416257 -0.0513381   0.18221745 -0.2269297\n",
      "   0.52433205 -0.32025084 -0.37138402 -0.36402878  0.30389526  0.4112642\n",
      "   0.52721965  0.47990587  0.04023483  0.09704001  0.4101433  -0.10024627\n",
      "  -0.07140119 -0.09453407  0.10833506  0.49695143  0.22503349 -0.13413307\n",
      "  -0.43885013  0.38638055  0.37065953 -0.6361621   1.1041517  -0.52603954\n",
      "  -0.03721397  0.00188479]\n",
      " [-0.03383374 -1.073238   -0.10827561 -0.3770589  -0.04454645  0.99133813\n",
      "   0.1728643  -0.41228953  0.9367252   0.25081062  0.45655185 -0.10865249\n",
      "   0.13452902 -0.3733003  -0.2729457  -0.3902837   0.78788215  0.21597287\n",
      "   0.12681794  0.6188102   0.3937391  -0.22010706 -0.16524439  0.1715139\n",
      "   0.62281007 -0.6713843   0.14313497 -0.27992478  0.03720408 -1.1283947\n",
      "   0.14400722 -0.60402185]\n",
      " [-0.08305543 -0.36063328  0.14059104 -0.1937322  -0.11987968  0.81303215\n",
      "  -0.04964341 -0.5511078  -0.30684078 -0.4127652  -0.4353055  -0.00629298\n",
      "   0.26708293 -0.22403869  0.2262981   0.23509689  0.32454118 -0.2252325\n",
      "  -0.42814898  0.36802095  0.324234   -0.26231322 -0.22977783 -0.57456005\n",
      "   0.6332278   0.3514276   0.34214568 -0.35710546 -0.6859498   0.33042186\n",
      "   0.07553577  0.09344206]\n",
      " [ 0.3124345  -0.60442924  0.4084807  -0.03230966  0.07106813 -0.43681324\n",
      "   0.20949906 -0.11233681 -0.7336104   0.44825777  0.14224513  0.06099168\n",
      "  -0.11886815 -0.33771306  0.35582295  0.16896147  0.8024196  -0.17447744\n",
      "   0.47393605 -0.0054733   0.5681115   0.18276374 -0.7514754   0.5315421\n",
      "  -0.49542874 -0.3214472  -0.17130603  0.2017954  -0.6090857   0.80497104\n",
      "   0.35691392 -0.30596998]\n",
      " [ 0.1888875  -0.2718455   0.16069151  0.21915796 -0.50494623  0.04095325\n",
      "   0.23494904  0.4756636   0.29585662  0.08960868  0.37720108 -0.33704516\n",
      "  -0.24432564 -0.7689749  -0.26877865  0.05471845  1.0233362  -0.12229028\n",
      "   0.6718536  -0.3509149   0.64678717  0.29761517  1.263705   -0.23840314\n",
      "  -0.10540022  0.47498056 -0.17206937  0.02607266  0.5834892  -0.10827689\n",
      "  -0.7549854  -1.0087347 ]\n",
      " [-0.33904296 -0.29083434  0.66905385 -0.58626324 -0.33361357  0.1214164\n",
      "  -0.85269713 -0.79284036  0.1744217   0.0889573   0.23531432  0.02410845\n",
      "   0.20683734 -0.4478082  -0.6180466  -0.14412946 -0.14292535 -0.00958976\n",
      "  -1.0371901   0.675155    0.17381114 -0.49054563 -0.27868298  0.10051141\n",
      "   0.06864425 -0.01591099  0.13054352  0.05786507  0.2384932  -0.16951218\n",
      "  -0.08034482  0.39299038]\n",
      " [ 0.23070776  0.16798964  0.33063945 -0.35199293 -0.17676014  0.37762758\n",
      "  -0.5796956  -0.16384773 -0.03653144  0.23752935 -0.0116851  -0.22282586\n",
      "   0.34425426 -0.07545346  0.267101   -0.13149217 -0.02672539  0.20525955\n",
      "  -0.7361815   0.1802131  -0.07077067 -0.02748206 -0.19113563 -0.08349652\n",
      "  -0.18965377  0.07849208  0.03201833  0.00742934  0.5088138  -0.05104238\n",
      "   0.18103552  0.21092264]\n",
      " [-0.33551678 -0.08024925 -0.40099594  0.02820537 -0.6846286   0.07635964\n",
      "   0.46267775 -0.4287313   0.3397569   0.55392003 -0.5892438  -0.10881517\n",
      "  -0.58245677  0.6070931   0.42219478 -0.31040883 -0.3231057  -0.10604861\n",
      "  -0.9825311  -0.14214931 -0.3504374   0.4288361   0.62448     0.571665\n",
      "  -0.07942472 -0.05977925 -0.38525632  0.00221896 -0.34804362 -0.57566655\n",
      "  -0.39851582 -0.38830778]\n",
      " [-0.30376437 -0.19010736  0.42378104  0.07032    -0.17741379  0.36433104\n",
      "   0.52501744  0.20013814 -0.29021445 -0.09686024  0.11790206  0.39098218\n",
      "  -0.16096257  0.46808505 -0.2018834  -0.40748903 -0.17829421 -0.20109408\n",
      "   0.7418599  -0.15100491 -0.4136447   0.45581388  0.23389485 -0.00346116\n",
      "  -0.35897812 -0.07598486 -0.11151028 -0.40482292  0.69946915  0.54394734\n",
      "  -0.00780002  0.07174309]\n",
      " [ 0.54814255  0.04626041  0.12494329 -0.02249026  0.59590745  0.07549887\n",
      "  -0.35018653 -0.0421505   0.06838569 -0.5069332  -0.28041527  0.25477287\n",
      "   0.15685616 -0.11431929 -0.18580572  0.02572076 -0.05167795  0.0624638\n",
      "   0.7807722  -0.13030772  0.01231936 -0.34307483 -0.0695966  -0.603121\n",
      "  -0.10344255  0.00391771  0.09996232 -0.08756118 -0.10251713  0.17076033\n",
      "  -0.3665445  -0.35417768]\n",
      " [ 0.7350618  -0.2506685  -0.03600247 -0.23743837  0.494603    0.15961942\n",
      "  -0.17877802  0.9377383   0.16947696 -0.973179   -0.59720904  0.00836741\n",
      "  -0.35353276 -0.6568333   0.48210055 -0.01942998  0.30486757  0.19305067\n",
      "  -0.4745549   0.14057195  0.5283838  -0.12876916 -0.22956373 -0.6961258\n",
      "   0.2673047  -0.03047036 -0.16447008 -0.32236186 -0.41454107  0.208765\n",
      "  -0.22752292 -0.70547545]\n",
      " [ 0.35636118 -0.29189324 -0.6242686  -0.35902637  0.1589337  -0.63957226\n",
      "  -0.03492603 -0.346007   -0.13426451 -0.2990312   0.27812797  1.1395313\n",
      "   0.6756753   0.19406033  0.23722704 -0.4559933  -0.00251651  0.43736807\n",
      "  -1.3976442   0.0162436   0.07335278 -0.2665449  -0.10233345  0.00885932\n",
      "  -0.26566705  1.429232    0.6963717  -0.37784076  0.27750275 -0.38322127\n",
      "  -0.14382587  0.10290166]\n",
      " [ 0.2815074  -0.17611013  0.08936629 -0.4067364  -0.64683014  0.0999133\n",
      "  -0.34983492 -0.3755761   0.06517445  0.3110255  -0.37810594 -0.1830167\n",
      "  -0.14529787  0.19869523 -0.4828223   0.10599789  0.08592219  0.00552452\n",
      "   0.19376267 -0.38784525  0.3414753  -0.32514182  0.36482996 -0.11932795\n",
      "   0.07473606  0.17423952 -0.24154432  0.3702914   0.44585913  0.2958741\n",
      "  -0.5300735   0.18711317]\n",
      " [-0.12352536 -0.77447206  0.5585232  -0.36786464 -0.49891746  0.36488593\n",
      "  -0.39128262  0.00502058 -0.03638394  0.0362514   0.05991173 -0.40704373\n",
      "  -0.51426584  0.09683315 -0.30735993  0.18032478 -0.12635657  0.2723073\n",
      "   0.677436   -0.21592277  0.12432363 -0.2707152   0.01367216  0.2869707\n",
      "   0.43314    -0.25209364 -0.22774208  0.44269508  0.13528073  0.58730817\n",
      "   0.09919665 -0.04101044]\n",
      " [-0.17271258  0.28510588 -0.14553504 -0.15929358  0.14147207 -0.18885356\n",
      "  -1.1183419   0.05035489 -0.01020242 -0.10498026 -1.5006456   0.25820917\n",
      "   0.13425979 -0.9201556   0.28227273 -0.04374697 -0.04448795 -0.16959919\n",
      "   0.45788598 -0.09410541 -0.11098682 -0.95912415 -0.3268954   0.00413214\n",
      "  -0.21128687  0.75104725  0.45175427  0.32603812 -0.81559086  0.22057785\n",
      "   0.09968401  1.1080986 ]\n",
      " [ 0.23161004  0.35782447 -0.13125342  0.4342771  -0.39042044 -0.12219946\n",
      "   0.3845675   0.41461697  0.15132886 -0.06296252  0.17404786  0.06352811\n",
      "  -0.16388233  0.20481537  0.29478166  0.23612873  0.04313333 -0.16803306\n",
      "  -0.87548786  0.1103965   0.04170081  0.47009927 -0.01474201 -0.39249995\n",
      "  -0.30334088  0.20142664 -0.14302982 -0.41229674  0.18254606 -0.5749259\n",
      "  -0.3089029  -0.14752942]]\n",
      "\n",
      "Hidden -> Output Layer bias:\n",
      " [ 0.01598931 -0.01600521]\n",
      "\n",
      "Hidden -> Output Layer weights:\n",
      " [[-0.87719303  0.78231966]\n",
      " [-0.62078893  0.4634361 ]\n",
      " [ 0.8069506  -0.81460524]\n",
      " [-0.57563204  0.46519992]\n",
      " [-0.55441827  0.5699131 ]\n",
      " [ 1.0702775  -0.8677746 ]\n",
      " [-0.42149007  0.8053521 ]\n",
      " [-0.87579906  0.7053041 ]\n",
      " [ 0.99706334 -1.4639252 ]\n",
      " [ 0.67302775 -0.80013865]\n",
      " [-1.8114235   1.6796937 ]\n",
      " [-0.55398184  0.5522448 ]\n",
      " [-0.42153287  0.7529308 ]\n",
      " [-1.3757756   0.7798895 ]\n",
      " [-0.756035    0.7519293 ]\n",
      " [ 0.3260798  -0.34281942]\n",
      " [-1.3374993   1.3816394 ]\n",
      " [ 0.06822529  0.0851948 ]\n",
      " [ 0.7799513  -0.7003658 ]\n",
      " [ 0.07542296 -0.40808177]\n",
      " [-0.54090077  0.27055404]\n",
      " [-0.68237966  0.20878868]\n",
      " [-0.571729    0.6810318 ]\n",
      " [ 0.6912416  -0.78883   ]\n",
      " [ 0.9463304  -0.6512562 ]\n",
      " [-0.9405643   0.87681264]\n",
      " [-0.7315122   0.74020916]\n",
      " [ 0.6847161  -0.42627984]\n",
      " [-1.044929    1.4814417 ]\n",
      " [ 1.3975158  -0.6947593 ]\n",
      " [-0.39341533  0.34141305]\n",
      " [-0.9255018   0.7297033 ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model info\n",
    "model.summary()\n",
    "\n",
    "norm_layer_weights = model.layers[0].get_weights()[0] #weight\n",
    "norm_layer_biases  = model.layers[0].get_weights()[1] #bias\n",
    "hidden_layer_weights = model.layers[1].get_weights()[0] #weight\n",
    "hidden_layer_biases  = model.layers[1].get_weights()[1] #bias\n",
    "out_layer_weights = model.layers[2].get_weights()[0] #weight\n",
    "out_layer_biases  = model.layers[2].get_weights()[1] #bias\n",
    "print('\\nInput -> Normalization Layer bias:\\n',norm_layer_biases)\n",
    "print('\\nInput -> Normalization Layer weights:\\n',norm_layer_weights)\n",
    "print('\\nNormalization -> Hidden Layer bias:\\n',hidden_layer_biases)\n",
    "print('\\nNormalization -> Hidden Layer weights:\\n',hidden_layer_weights)\n",
    "print('\\nHidden -> Output Layer bias:\\n',out_layer_biases)\n",
    "print('\\nHidden -> Output Layer weights:\\n',out_layer_weights,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1716259966440,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "hqqrljwkNZ_p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-07-2024-16-46-44\n"
     ]
    }
   ],
   "source": [
    "# Date for report file\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "print(dt_string)\n",
    "# Report file content\n",
    "report = {\n",
    "    \"datetime\": dt_string,\n",
    "    \"number_of_attributes\": number_of_attributes,\n",
    "    \"hidden_layer_nodes\": hidden_layer_nodes,\n",
    "    \"output_layer_nodes\": output_layer_nodes,\n",
    "    \"accuracy_test\": one_test_acc,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS\n",
    "    #\"number_of_samples\": number_of_samples,\n",
    "    #\"df_number\": df_number\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5378,
     "status": "ok",
     "timestamp": 1716259977049,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "DL5sxqffj2co"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\NN-P4\\tf-params-reports\n",
      "C:\\NN-P4\\tf-models\n"
     ]
    }
   ],
   "source": [
    "#TO DO: use save_models instead of save_weights\n",
    "\n",
    "# Model parameters json file generation, create file with date-time string to prevent unwated/accidental overwrites\n",
    "os.chdir('../tf-params-reports/')\n",
    "print(os.getcwd())\n",
    "\n",
    "title_parameters_save = f\"nn-nprint-{use_case}-model-parameters-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.json\"\n",
    "with open(title_parameters_save, \"w\") as f:\n",
    "  json.dump(report, f)\n",
    "\n",
    "title_parameters_save = f\"nn-nprint-{use_case}-model-parameters-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}-{dt_string}.json\"\n",
    "with open(title_parameters_save, \"w\") as f:\n",
    "  json.dump(report, f)\n",
    "\n",
    "# Model file with weights and other params\n",
    "os.chdir('../tf-models/') \n",
    "print(os.getcwd())\n",
    "\n",
    "title_model_save = f'nn-nprint-{use_case}-model-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.keras'\n",
    "model.save(title_model_save)\n",
    "\n",
    "# Model weights file generation\n",
    "# os.chdir('../tf-model-weights/')\n",
    "# print(os.getcwd())\n",
    "\n",
    "# title_model_save = f'nn-nprint-model-weights-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.weights.h5'\n",
    "# model.save_weights(title_model_save) # Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "\n",
    "# title_model_save = f'nn-nprint-model-weights-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}-{dt_string}.weights.h5'\n",
    "# model.save_weights(title_model_save) # Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "    \n",
    "# model.load_weights(f'nn-nprint-app-iden-model-weights-{number_of_attributes}x{hidden_layer_nodes}x{output_layer_nodes}.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acervo - comandos úteis os python\n",
    "# %pwd\n",
    "# os.chdir(C:\\NN-P4\\nn-reports)\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "# os.listdir()\n",
    "# os.chdir('../nn-reports/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 1108,
     "status": "error",
     "timestamp": 1716259692331,
     "user": {
      "displayName": "Vicente Lessa",
      "userId": "14551761473643883791"
     },
     "user_tz": 180
    },
    "id": "OsFlOvQqF-KK",
    "outputId": "7f2b6ca8-0e18-477c-c605-075a9a5eeb1a"
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/X.pkl')\n",
    "# df_test = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/X_val.pkl')\n",
    "# label_train = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/y.pkl')\n",
    "# label_test = pd.read_pickle('/content/drive/MyDrive/nprint/nn-reproduction/app-iden/y_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIH1M4SDzT/02evItuJvc2",
   "provenance": [
    {
     "file_id": "1N0tN69OVtNS4K7h67xdyUtJ0_hWbDa9x",
     "timestamp": 1701094766071
    },
    {
     "file_id": "18-qqwOnAL89_m5Lb45uZ40u1ut46iuIU",
     "timestamp": 1690808958392
    },
    {
     "file_id": "19JxEc2VYTW6pRVyhOmnsRVPvksE5gBBN",
     "timestamp": 1661778258249
    },
    {
     "file_id": "1u0E4CFsBf4k62yi38gfqB4HlagC-Tfhc",
     "timestamp": 1661541388425
    },
    {
     "file_id": "1Cpg4jNgwyPiT4AGenVm1xCQgBrzxHhCT",
     "timestamp": 1643821363627
    },
    {
     "file_id": "1k-uty64gq4zwMYT-FFDYnhQ-9Z5bXvQ-",
     "timestamp": 1642608790480
    },
    {
     "file_id": "1eXxWzQSIUjunkjCGopzkFpuoB42a7YbS",
     "timestamp": 1642604110588
    },
    {
     "file_id": "1Y0hheLUxBgA_oy3QG9nY0JRieWhjt4BM",
     "timestamp": 1639758139710
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
